
# StableLM Chat Application

This is a simple chat application that uses the StableLM 2 1.6B model for generating responses.

## Setup

1. Clone the repository:
   ```
   git clone https://github.com/raditself/q.git
   cd q
   ```

2. Install the required packages:
   ```
   pip install flask flask-cors ctransformers requests
   ```

3. Run the application:
   ```
   python app.py
   ```

4. Open `index.html` in your web browser to start chatting.

## Features

- Simple web interface for chatting
- Uses StableLM 2 1.6B model for generating responses
- Automatic model download on first run

## Note

This application is for demonstration purposes only and should not be used in production environments without proper security measures.
